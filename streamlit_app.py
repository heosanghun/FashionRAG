# streamlit_app.py
# Streamlit Cloud ë°°í¬ìš© FashionRAG ì• í”Œë¦¬ì¼€ì´ì…˜

import os
import streamlit as st
from dotenv import load_dotenv
import chromadb
import base64
from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction
from chromadb.utils.data_loaders import ImageLoader
from datasets import load_dataset
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from pathlib import Path

# OpenAI API í‚¤ ì„¤ì •
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.error("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloudì˜ Secretsì—ì„œ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

# ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ ë””ë ‰í„°ë¦¬ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))

@st.cache_resource
def setup_dataset():
    """
    Fashionpedia ë°ì´í„°ì…‹ì„ ì„¤ì •í•©ë‹ˆë‹¤.
    """
    try:
        with st.spinner("ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ëŠ” ì¤‘..."):
            dataset = load_dataset("detection-datasets/fashionpedia")
        
        dataset_folder = os.path.join(SCRIPT_DIR, 'fashion_dataset')
        os.makedirs(dataset_folder, exist_ok=True)
        
        st.success(f"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {len(dataset['train'])} í›ˆë ¨ ì´ë¯¸ì§€, {len(dataset['val'])} ê²€ì¦ ì´ë¯¸ì§€")
        return dataset, dataset_folder
    except Exception as e:
        st.error(f"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None, None

def save_images(dataset, dataset_folder, num_images=100):
    """
    ë°ì´í„°ì…‹ ì´ë¯¸ì§€ë¥¼ ë¡œì»¬ í´ë”ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    with st.spinner(f"{num_images}ê°œ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•˜ëŠ” ì¤‘..."):
        for i in range(min(num_images, len(dataset['train']))):
            image = dataset['train'][i]['image']
            image.save(os.path.join(dataset_folder, f'image_{i+1}.png'))
    st.success(f"âœ… {min(num_images, len(dataset['train']))}ê°œ ì´ë¯¸ì§€ë¥¼ {dataset_folder}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

@st.cache_resource
def setup_chroma_db():
    """
    ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    """
    vdb_path = os.path.join(SCRIPT_DIR, 'img_vdb')
    chroma_client = chromadb.PersistentClient(path=vdb_path)
    image_loader = ImageLoader()
    clip_embedder = OpenCLIPEmbeddingFunction()
    image_vdb = chroma_client.get_or_create_collection(
        name="image_vdb",
        embedding_function=clip_embedder,
        data_loader=image_loader
    )
    return image_vdb

def add_images_to_db(image_vdb, dataset_folder):
    """
    ì´ë¯¸ì§€ë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    ids = []
    uris = []
    for i, filename in enumerate(sorted(os.listdir(dataset_folder))):
        if filename.endswith('.png'):
            file_path = os.path.join(dataset_folder, filename)
            ids.append(str(i+1))
            uris.append(file_path)

    if ids:
        with st.spinner(f"{len(ids)}ê°œ ì´ë¯¸ì§€ë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€í•˜ëŠ” ì¤‘..."):
            image_vdb.add(ids=ids, uris=uris)
        st.success(f"âœ… {len(ids)}ê°œ ì´ë¯¸ì§€ê°€ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        st.warning("âš ï¸ ì¶”ê°€í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

def query_db(image_vdb, query, results=2):
    """
    ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì´ë¯¸ì§€ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    return image_vdb.query(
        query_texts=[query],
        n_results=results,
        include=['uris', 'distances']
    )

@st.cache_data
def translate(text, target_lang):
    """
    í…ìŠ¤íŠ¸ë¥¼ ë²ˆì—­í•©ë‹ˆë‹¤.
    """
    translation_model = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.0)
    translation_prompt = ChatPromptTemplate.from_messages([
        ("system", f"You are a translator. Translate the following text to {target_lang}."),
        ("user", "{text}")
    ])
    translation_chain = translation_prompt | translation_model | StrOutputParser()
    return translation_chain.invoke({"text": text})

def setup_vision_chain():
    """
    ë©€í‹°ëª¨ë‹¬ ë¹„ì „ ì²´ì¸ì„ ì„¤ì •í•©ë‹ˆë‹¤.
    """
    gpt4 = ChatOpenAI(model="gpt-4o", temperature=0.0)
    parser = StrOutputParser()
    image_prompt = ChatPromptTemplate.from_messages([
        ("system", "You are a helpful fashion and styling assistant. Answer the user's question using the given image context with direct references to parts of the images provided. Maintain a more conversational tone, don't make too many lists. Use markdown formatting for highlights, emphasis, and structure."),
        ("user", [
            {"type": "text", "text": "What are some ideas for styling {user_query}?"},
            {"type": "image_url", "image_url": "data:image/jpeg;base64,{image_data_1}"},
            {"type": "image_url", "image_url": "data:image/jpeg;base64,{image_data_2}"},
        ])
    ])
    return image_prompt | gpt4 | parser

def format_prompt_inputs(data, user_query):
    """
    í”„ë¡¬í”„íŠ¸ ì…ë ¥ì„ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    """
    inputs = {'user_query': user_query}
    
    # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì¸ì½”ë”©
    with open(data['uris'][0][0], 'rb') as f:
        inputs['image_data_1'] = base64.b64encode(f.read()).decode('utf-8')
    
    # ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ ì¸ì½”ë”©
    with open(data['uris'][0][1], 'rb') as f:
        inputs['image_data_2'] = base64.b64encode(f.read()).decode('utf-8')
    
    return inputs

def main():
    """
    ë©”ì¸ í•¨ìˆ˜: Streamlit ì•± ì‹¤í–‰
    """
    st.set_page_config(
        page_title="FashionRAG - íŒ¨ì…˜ ìŠ¤íƒ€ì¼ë§ ì–´ì‹œìŠ¤í„´íŠ¸",
        page_icon="ğŸ‘—",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.title("ğŸ¨ FashionRAG ì„¤ì •")
    st.sidebar.markdown("**AI ê¸°ë°˜ íŒ¨ì…˜ ìŠ¤íƒ€ì¼ë§ ì–´ì‹œìŠ¤í„´íŠ¸**")
    
    # ë©”ì¸ íƒ€ì´í‹€
    st.title("ğŸ‘— FashionRAG: íŒ¨ì…˜ ìŠ¤íƒ€ì¼ë§ ì–´ì‹œìŠ¤í„´íŠ¸")
    st.markdown("**ë©€í‹°ëª¨ë‹¬ RAG ê¸°ë°˜ íŒ¨ì…˜ ìŠ¤íƒ€ì¼ë§ ì¡°ì–¸ ì‹œìŠ¤í…œ**")
    
    # ë°ì´í„°ì…‹ ë° ë²¡í„°DB ì´ˆê¸°í™”
    if 'data_initialized' not in st.session_state:
        with st.spinner("ë°ì´í„°ì…‹ê³¼ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            # 1. ë°ì´í„°ì…‹ ì„¤ì •
            dataset, dataset_folder = setup_dataset()
            if not dataset:
                st.error("âŒ ë°ì´í„°ì…‹ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                st.stop()
            
            # 2. ì´ë¯¸ì§€ ì €ì¥ (ì²˜ìŒ ì‹¤í–‰ì‹œì—ë§Œ)
            if not os.path.exists(dataset_folder) or not any(fname.endswith('.png') for fname in os.listdir(dataset_folder)):
                save_images(dataset, dataset_folder, num_images=100)
            
            # 3. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
            vdb_path = os.path.join(SCRIPT_DIR, 'img_vdb')
            if not os.path.exists(vdb_path):
                st.session_state.image_vdb = setup_chroma_db()
                add_images_to_db(st.session_state.image_vdb, dataset_folder)
            else:
                st.session_state.image_vdb = setup_chroma_db()
                st.success("âœ… ê¸°ì¡´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            
            # 4. ë¹„ì „ ì²´ì¸ ì„¤ì •
            st.session_state.vision_chain = setup_vision_chain()
            
        st.session_state.data_initialized = True
        st.success("ğŸ‰ FashionRAG ì´ˆê¸°í™” ì™„ë£Œ!")
    
    # ì‚¬ìš©ì ì…ë ¥ ì„¹ì…˜
    st.header("ğŸ’¬ íŒ¨ì…˜ ìŠ¤íƒ€ì¼ë§ ì§ˆë¬¸í•˜ê¸°")
    
    # ì˜ˆì‹œ ì§ˆë¬¸ë“¤
    example_questions = [
        "í•˜ëŠ˜ìƒ‰ ê³„ì—´ì˜ ìºì£¼ì–¼í•œ ì—¬ë¦„ ì½”ë”” ì¶”ì²œí•´ì¤˜",
        "ë¹„ì¦ˆë‹ˆìŠ¤ ìºì£¼ì–¼ ë£© ì–´ë–»ê²Œ êµ¬ì„±í•˜ë©´ ì¢‹ì„ê¹Œ?",
        "ê²€ì€ìƒ‰ ë“œë ˆìŠ¤ì— ì–´ìš¸ë¦¬ëŠ” ì•¡ì„¸ì„œë¦¬ ì¶”ì²œí•´ì¤˜",
        "ë‚¨ì„±ìš© ê²¨ìš¸ ì½”íŠ¸ ìŠ¤íƒ€ì¼ë§ ë°©ë²• ì•Œë ¤ì¤˜",
        "ë¯¸ë‹ˆë©€í•œ ë°ì¼ë¦¬ ë£© êµ¬ì„±ë²•"
    ]
    
    # ì˜ˆì‹œ ì§ˆë¬¸ ì„ íƒ
    selected_example = st.selectbox(
        "ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸ì„ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”:",
        ["ì§ì ‘ ì…ë ¥"] + example_questions
    )
    
    if selected_example == "ì§ì ‘ ì…ë ¥":
        query_ko = st.text_input(
            "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
            placeholder="ì˜ˆ: í•˜ëŠ˜ìƒ‰ ê³„ì—´ì˜ ìºì£¼ì–¼í•œ ì—¬ë¦„ ì½”ë”” ì¶”ì²œí•´ì¤˜"
        )
    else:
        query_ko = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", value=selected_example)
    
    # ì§ˆë¬¸í•˜ê¸° ë²„íŠ¼
    if st.button("ğŸš€ ì§ˆë¬¸í•˜ê¸°", type="primary", width='stretch'):
        if not query_ko.strip():
            st.warning("âš ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("íŒ¨ì…˜ ìŠ¤íƒ€ì¼ë§ ì¡°ì–¸ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    # 1. ì§ˆë¬¸ ë²ˆì—­ (í•œê¸€ -> ì˜ì–´)
                    with st.expander("ğŸ“ ë²ˆì—­ ê³¼ì •", expanded=False):
                        query_en = translate(query_ko, "English")
                        st.write(f"**ì›ë³¸ ì§ˆë¬¸:** {query_ko}")
                        st.write(f"**ë²ˆì—­ëœ ì§ˆë¬¸:** {query_en}")
                    
                    # 2. ì´ë¯¸ì§€ ê²€ìƒ‰
                    results = query_db(st.session_state.image_vdb, query_en, results=2)
                    
                    # 3. í”„ë¡¬í”„íŠ¸ ì…ë ¥ í¬ë§·íŒ…
                    prompt_input = format_prompt_inputs(results, query_en)
                    
                    # 4. ìŠ¤íƒ€ì¼ë§ ì¡°ì–¸ ìƒì„±
                    response_en = st.session_state.vision_chain.invoke(prompt_input)
                    
                    # 5. ì‘ë‹µ ë²ˆì—­ (ì˜ì–´ -> í•œê¸€)
                    response_ko = translate(response_en, "Korean")
                    
                    # ê²°ê³¼ ì¶œë ¥
                    st.header("ğŸ¯ FashionRAGì˜ ìŠ¤íƒ€ì¼ë§ ì¡°ì–¸")
                    
                    # ê²€ìƒ‰ëœ ì´ë¯¸ì§€ í‘œì‹œ
                    st.subheader("ğŸ–¼ï¸ ê²€ìƒ‰ëœ íŒ¨ì…˜ ì´ë¯¸ì§€")
                    cols = st.columns(2)
                    for i, uri in enumerate(results['uris'][0]):
                        with open(uri, "rb") as f:
                            img_bytes = f.read()
                            encoded_img = base64.b64encode(img_bytes).decode()
                            cols[i].image(
                                f"data:image/png;base64,{encoded_img}",
                                caption=f"ì´ë¯¸ì§€ ID: {results['ids'][0][i]} (ìœ ì‚¬ë„: {results['distances'][0][i]:.3f})",
                                width='stretch'
                            )
                    
                    # ìŠ¤íƒ€ì¼ë§ ì¡°ì–¸ í‘œì‹œ
                    st.subheader("ğŸ’¡ íŒ¨ì…˜ ìŠ¤íƒ€ì¼ë§ ì¡°ì–¸")
                    st.markdown(response_ko)
                    
                    # ì›ë³¸ ì˜ì–´ ì‘ë‹µ (ì ‘ê¸°)
                    with st.expander("ğŸ” ì›ë³¸ ì˜ì–´ ì‘ë‹µ ë³´ê¸°", expanded=False):
                        st.markdown(response_en)
                    
                except Exception as e:
                    st.error(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    st.info("ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    
    # ì •ë³´ ì„¹ì…˜
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´")
    st.sidebar.markdown(f"""
    - **ë°ì´í„° ì†ŒìŠ¤**: HuggingFace Fashionpedia
    - **ì´ ì´ë¯¸ì§€**: 46,781ê°œ
    - **AI ëª¨ë¸**: GPT-4o
    - **ë²¡í„° DB**: ChromaDB
    - **ì´ë¯¸ì§€ ì„ë² ë”©**: OpenCLIP
    """)
    
    # ë°°í¬ ì •ë³´
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸš€ ë°°í¬ ì •ë³´")
    st.sidebar.markdown("**Streamlit Cloudì—ì„œ í˜¸ìŠ¤íŒ…ë¨**")

if __name__ == "__main__":
    main()
